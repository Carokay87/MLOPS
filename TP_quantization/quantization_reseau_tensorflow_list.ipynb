{"cells":[{"cell_type":"markdown","source":"## Introduction à la quantization \n\nLaurent cetinsoy\n\nLes réseaux de neurones prennent beaucoup de place et il peut être difficile de les faire rentrer sur certains dispositifs embarqués. \n\nIl existe plusieurs méthodes pour réduire la taille et augmenter la vitesse d'executer des réseaux de neurone. Par exemple il y a ce qu'on appelle la quantization et le pruning.\n\nDans ce notebook on va faire une introduction à la quantization avec la librairie tensorflow lite.\n\n\n## Quantization post training\n\nDans un premier temps on va quantifier notre réseau après l'avoir entraîné normalement. \n\n\nEntraîner un réseau de neurone convolutionnel simple avec keras pour faire de la classification MNIST (ou un autre dataset simple de votre choix si (vous en avez marre de ce dataset - https://keras.io/api/datasets/)\n\n\n","metadata":{"tags":[],"cell_id":"efc9100a06c04d0b8b17c557d7cbbd41","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"87bc3d9f649e416983c0ee9b59bd2de6","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Afficher le nombre de paramètre du modèle","metadata":{"tags":[],"cell_id":"b984ac621a2249d1b955535f9f9ab55b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"11935acab177492cbcd4a8aafea0bdf0","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sauvegarder votre modèle et afficher la taille du fichier. Si on applique une bête règle de trois, quelle est la taille occupée par paramètre ? ","metadata":{"tags":[],"cell_id":"4782a0f186d14d4e91cfd903998f8710","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"8f50426e286c4cf39610c41ed5cdfeb7","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"On va maintenant convertir notre modèle keras en modèle tensorflow lite. \n\nInstaller la librairie tensorflow lite créer une instance de la class TFLiteConverter à partir de votre modèle keras\n","metadata":{"tags":[],"cell_id":"2e0f0d5c02dc40db9fae96aa67d4de06","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"8c1f6d62ff6a416aa3ec3b05ebccddb9","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Convertir votre modèle et le sauvegarder dans un fichier nommé model.tflite. Sa taille est-elle plus petite ? ","metadata":{"tags":[],"cell_id":"13a2cc6cc09f4e799d4e8641521ece8e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"2ca07a9b6ee74a6594c3a33313decfc0","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"On va maintenant spécifier des optimisations au converter. \n\n1. Recréer un converter\n\n2. modifier son attribut optimizations pour ajouter une liste d'optimisation avec la valeur tf.lite.Optimize.DEFAULT\n\n3. Relancer la conversion du modèle, sauvegarder le modèle et regarder la taille du fichier généré","metadata":{"tags":[],"cell_id":"0e707074068f44ffad07b9301948782b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"42b10a79262949aeadb6f2f82eae6f58","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Quelle type  de quantization Optimize.Default, utilise-t-elle ?\n","metadata":{"tags":[],"cell_id":"e083971b3c7647818e1532ed9c7edb41","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"c4952d60d77243439193b6e9b4d573e9","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Quantization aware training \n\nDans cette section on va s'intéresser à l'entraînement sensible à la quantification. L'idée est de simuler les effets de la quantification pendant l'entraînement pour que le modèle ajuste les poids afin de tenir ocmpte de la quantification. \n\nReprendre le modèle entraîné sur MNIST\n","metadata":{"tags":[],"cell_id":"0bfeb7a588454ae6942059d7d79be609","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"11d35b87030b49eb99c77c4a6fe47db3","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A l'aide de la fonction quantize de tensorflow_model_optimization, créer une seconde version de votre modèle entraîné nommé qat_model","metadata":{"tags":[],"cell_id":"af90aac8bbb94f86b728031f5ae0a66f","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"3558b441b2b6461d8ada14a483cf14f6","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Compiler le modèle","metadata":{"tags":[],"cell_id":"868beffe9e8740d98cbfd8458af4117a","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"a44bf47bba4746789745d44d3421a374","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Afficher le summury du modèle. D'après vous ce modèle est-il quantifié ? ","metadata":{"tags":[],"cell_id":"4dddea973f404fb699b134a67d1a2dc5","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"169400c0d68d417a8fc0acd42e3d8b4f","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Réentraîner votre modèle sur un sous ensemble des modèles sur une ou deux epochs et afficher la performance sur le train et test set","metadata":{"tags":[],"cell_id":"7b3a873512174205b6d6f4aacd7480c8","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"487c400c11454184b5d55729476d81c3","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Convertir votre modèle avec TFLite","metadata":{"tags":[],"cell_id":"cc4f49a0e7894b8385e90c2330a55bb1","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"68918464bfb14b749d3848fe25b5e02e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Comparer la performance du modèle Quantified aware training, au modèle original et au modèle quantifié post training","metadata":{"tags":[],"cell_id":"d80e6fbfea9646919a9cbe2c8fa41b2d","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"bdd43405f5fd46ce892d957bb43a353a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sauvegarder le modèle QAT et comparer les tailles des modèles","metadata":{"tags":[],"cell_id":"6472c7a129394639838f76381e562588","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"d3c2951a1fd14be3b5e3c85e05a056ea","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bonus : déployer votre modèle sur votre téléphone ou un dispositif embarqué si vous en disposez d'un. ","metadata":{"tags":[],"cell_id":"4a006a6d1a194e418072192da1a920de","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"927af747794641fa936ad727c6bf75d0","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bonus : Obtenir un modèle qui sera à la fois quantifié et élagué (prunned) en s'aidant de la documentation (https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)","metadata":{"tags":[],"cell_id":"e7635cb278ab43589a851e2c2de0d8ef","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"a1eacb94d0aa4dbd872c8babacf8bb8d","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=0d51e245-899d-41d6-b23b-cf3e4bbbc6ea' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{"is_reactive":false},"orig_nbformat":2,"deepnote_notebook_id":"fb1d23f975ba410e92fed9f5b8cbb7e6","deepnote_execution_queue":[]}}